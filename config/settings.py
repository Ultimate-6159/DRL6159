# -*- coding: utf-8 -*-
"""
Apex Predator DRL Trading System -- Central Configuration
=========================================================
All system parameters in one place. No magic numbers scattered across modules.
"""

import os
from dataclasses import dataclass, field
from typing import List, Optional
from enum import Enum
from pathlib import Path

# Load .env from project root
try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).resolve().parent.parent / ".env")
except ImportError:
    pass  # python-dotenv not installed; rely on real env vars


# ??????????????????????????????????????????????
# Enums
# ??????????????????????????????????????????????

class MarketRegime(Enum):
    """Market state classification."""
    TRENDING = "trending"
    MEAN_REVERTING = "mean_reverting"
    HIGH_VOLATILITY = "high_volatility"
    UNCERTAIN = "uncertain"


class TradeAction(Enum):
    """Possible trade actions for the DRL agent."""
    BUY = 0
    SELL = 1
    HOLD = 2


# ??????????????????????????????????????????????
# MT5 Configuration
# ??????????????????????????????????????????????

@dataclass
class MT5Config:
    """MetaTrader 5 connection settings."""
    login: int = int(os.getenv("MT5_LOGIN", "0"))
    password: str = os.getenv("MT5_PASSWORD", "")
    server: str = os.getenv("MT5_SERVER", "")
    path: str = r"C:\Program Files\MetaTrader 5\terminal64.exe"
    symbol: str = "XAUUSDm"
    timeframe: str = "M5"               # M5 = better spread-to-ATR ratio (was M1)
    magic_number: int = 616159           # Unique EA identifier
    deviation: int = 20                  # Max slippage in points
    fill_type: str = "IOC"              # IOC, FOK, RETURN


# ??????????????????????????????????????????????
# Feature Engineering Configuration
# ??????????????????????????????????????????????

@dataclass
class FeatureConfig:
    """Parameters for feature construction."""
    lookback_window: int = 500           # Bars of history for LSTM input
    atr_period: int = 14                 # ATR calculation period
    spread_ma_period: int = 20           # Spread moving average period
    volume_profile_bins: int = 50        # Number of bins for volume profile
    z_score_window: int = 100            # Rolling z-score normalization window
    log_returns: bool = True             # Use log returns vs simple returns
    features: List[str] = field(default_factory=lambda: [
        "close", "high", "low", "volume",
        "spread", "atr", "returns", "z_score",
        "momentum", "rsi_raw",
        "ema_cross", "macd_signal", "bb_position",
        "body_ratio", "vol_spike",
        # Multi-Timeframe Context
        "adx", "ema50_distance",
        # Max Pain Theory features
        "vwap_distance", "trapped_sentiment", "pain_intensity",
    ])


# ??????????????????????????????????????????????
# Regime Classifier Configuration
# ??????????????????????????????????????????????

@dataclass
class RegimeConfig:
    """Parameters for market regime detection."""
    volatility_window: int = 50          # Window for volatility calculation
    trend_window: int = 100              # Window for trend detection
    hurst_window: int = 100              # Window for Hurst exponent
    regime_change_threshold: float = 0.3 # Min confidence for regime switch
    vol_ratio_threshold: float = 1.5     # High vol if ratio > this
    trend_strength_threshold: float = 0.6 # Strong trend if > this
    update_frequency: int = 10           # Re-evaluate regime every N bars


# ??????????????????????????????????????????????
# Perception (LSTM) Configuration
# ??????????????????????????????????????????????

@dataclass
class PerceptionConfig:
    """LSTM / Transformer neural network settings."""
    input_dim: int = 20                  # Number of features (20 after removing 6 correlated)
    hidden_dim: int = 128                # LSTM hidden state size
    num_layers: int = 2                  # Number of LSTM layers
    dropout: float = 0.2                 # Dropout rate
    embedding_dim: int = 64             # Output embedding dimension
    use_attention: bool = True           # Add attention layer on top
    sequence_length: int = 60            # Input sequence length for LSTM
    device: str = "auto"                 # "cpu", "cuda", or "auto"


# ??????????????????????????????????????????????
# DRL Agent Configuration
# ??????????????????????????????????????????????

@dataclass
class DRLConfig:
    """PPO / SAC reinforcement learning settings."""
    algorithm: str = "PPO"               # "PPO" or "SAC"
    learning_rate: float = 3e-4          # Higher start for LR Schedule (will decay)
    gamma: float = 0.99                  # Discount factor
    gae_lambda: float = 0.95            # GAE lambda
    clip_range: float = 0.2             # Standard clip
    n_steps: int = 8192                  # DOUBLED: more experience per update (was 4096)
    batch_size: int = 2048               # DOUBLED: smoother gradients (was 1024)
    n_epochs: int = 10                   # Standard epochs
    ent_coef: float = 0.01              # Very decisive: exploit > explore for scalping
    vf_coef: float = 0.5                # Value function coefficient
    max_grad_norm: float = 0.5          # Standard clipping
    target_kl: float = 0.03             # Tighter KL limit for stability
    normalize_advantage: bool = True     # Normalize advantages for stability
    total_timesteps: int = 5_000_000     # Train longer for speed-scalping convergence
    lookback: int = 30                   # Observation window in bars (was 10, too short)
    model_save_path: str = "models/"     # Model checkpoint directory
    tensorboard_log: str = "logs/tb/"    # TensorBoard log directory


# ??????????????????????????????????????????????
# Reward Configuration
# ??????????????????????????????????????????????

@dataclass
class RewardConfig:
    """Reward function parameters (Dynamic Profit Runner style)."""
    profit_reward: float = 2.0           # Strong reward for wins
    loss_penalty: float = -3.0           # Harsh loss penalty (inverted R:R needs high WR)
    hold_penalty: float = -0.05          # Pressure to exit fast
    max_hold_steps: int = 10             # 10 bars x M5 = 50 min max (speed scalping)
    drawdown_penalty: float = -5.0       # Strong drawdown aversion
    sharpe_window: int = 50              # Rolling window for Sharpe calc
    risk_free_rate: float = 0.0          # Risk-free rate for Sharpe
    optimal_close_bonus: float = 1.0     # Bonus for closing at good R:R


# ??????????????????????????????????????????????
# Risk Management Configuration
# ??????????????????????????????????????????????

@dataclass
class RiskConfig:
    """Hard-coded risk management parameters (Sniper style)."""
    max_risk_per_trade: float = 0.005    # 0.5% risk (smaller since inverted R:R)
    max_daily_loss: float = 0.03         # Max 3% daily drawdown
    max_total_drawdown: float = 0.15     # Max 15% total drawdown -> halt (wider for scalp drawdowns)
    max_concurrent_trades: int = 1       # SINGLE position only
    max_lot_size: float = 0.5            # Absolute max lot size
    min_lot_size: float = 0.01           # Minimum lot size
    atr_multiplier: float = 2.0          # SL = ATR * 2.0 (wide SL → avoid noise stop-outs)
    tp_ratio: float = 0.5                # TP = SL * 0.5 (INVERTED R:R → narrow TP → high WR)
    min_sl_spread_mult: float = 3.0      # SL must be >= 3x spread
    trade_cooldown_sec: int = 30          # 30 sec cooldown (trade frequently)


# ??????????????????????????????????????????????
# Circuit Breaker Configuration
# ??????????????????????????????????????????????

@dataclass
class CircuitBreakerConfig:
    """Emergency stop parameters."""
    max_consecutive_losses: int = 5      # Allow 5 consecutive losses (high WR recovers fast)
    cooldown_minutes: int = 15           # Shorter cooldown (don't miss opportunities)
    drawdown_halt_pct: float = 0.08      # Halt at 8% drawdown
    max_daily_trades: int = 200          # Allow more trades (high frequency target)
    spread_spike_multiplier: float = 3.0 # Halt if spread > 3x normal


# ??????????????????????????????????????????????
# Curriculum Learning Configuration
# ??????????????????????????????????????????????

@dataclass
class CurriculumConfig:
    """Progressive training: easy ? hard market conditions."""
    enabled: bool = True
    # Fraction of total timesteps per phase [trending, +ranging, all]
    phase_ratios: List[float] = field(default_factory=lambda: [0.30, 0.35, 0.35])
    min_segment_length: int = 100        # Min contiguous bars to form a segment


# ??????????????????????????????????????????????
# Imitation Learning Configuration
# ??????????????????????????????????????????????

@dataclass
class ImitationConfig:
    """Behavioral cloning pre-training from hindsight-optimal trades."""
    enabled: bool = True
    epochs: int = 10                     # BC training epochs
    learning_rate: float = 1e-3          # BC learning rate
    batch_size: int = 256                # Supervised mini-batch size
    lookahead_bars: int = 30             # How far to look ahead for oracle
    min_trend_strength: float = 0.6      # Only label bars with clear signal


# ??????????????????????????????????????????????
# Evolution / Self-Learning Configuration
# ??????????????????????????????????????????????

@dataclass
class EvolutionConfig:
    """Online learning and walk-forward optimization."""
    retrain_interval: int = 100          # Retrain after N completed trades
    replay_buffer_size: int = 50_000     # Max experiences in replay buffer
    min_retrain_samples: int = 500       # Min samples before retraining
    walk_forward_window: int = 5_000     # Bars for walk-forward testing
    walk_forward_step: int = 1_000       # Step forward by N bars
    performance_threshold: float = 0.3   # Min Sharpe to keep model
    model_history_count: int = 10        # Keep N model checkpoints
    checkpoint_interval_hours: int = 4   # Save model every N hours


# ??????????????????????????????????????????????
# Vector Memory Configuration
# ??????????????????????????????????????????????

@dataclass
class MemoryConfig:
    """Vector database for pattern memory."""
    embedding_dim: int = 64              # Must match PerceptionConfig
    max_memories: int = 100_000          # Max stored patterns
    recall_top_k: int = 5               # Top-K similar patterns to retrieve
    similarity_threshold: float = 0.7    # Min cosine similarity for recall
    persist_path: str = "data/memory/"   # Disk persistence path
    auto_save_interval: int = 10         # Auto-save every N new stores


# ??????????????????????????????????????????????
# Master Configuration
# ??????????????????????????????????????????????

@dataclass
class ApexConfig:
    """
    Master configuration aggregating all sub-configs.
    Instantiate this once and pass it to all modules.
    """
    mt5: MT5Config = field(default_factory=MT5Config)
    features: FeatureConfig = field(default_factory=FeatureConfig)
    regime: RegimeConfig = field(default_factory=RegimeConfig)
    perception: PerceptionConfig = field(default_factory=PerceptionConfig)
    drl: DRLConfig = field(default_factory=DRLConfig)
    reward: RewardConfig = field(default_factory=RewardConfig)
    risk: RiskConfig = field(default_factory=RiskConfig)
    circuit_breaker: CircuitBreakerConfig = field(default_factory=CircuitBreakerConfig)
    evolution: EvolutionConfig = field(default_factory=EvolutionConfig)
    memory: MemoryConfig = field(default_factory=MemoryConfig)
    curriculum: CurriculumConfig = field(default_factory=CurriculumConfig)
    imitation: ImitationConfig = field(default_factory=ImitationConfig)

    # Global
    dry_run: bool = True                 # True = mock mode, no real orders
    log_level: str = "INFO"              # DEBUG, INFO, WARNING, ERROR
    log_dir: str = "logs/"               # Log file directory
    data_dir: str = "data/"              # Data persistence directory
